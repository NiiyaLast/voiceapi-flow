ai:
  # provider: ollama   
  provider: deepseek      # 支持：ollama, openai, deepseek
  # api_url: http://localhost:11434
  api_url: https://api.deepseek.com/v1
  api_key: null           # 外部模型API密钥，ollama不需要
  enabled: true
  max_retries: 3
  # model_name: qwen3:1.7b
  model_name: deepseek-chat
  timeout: 60
  # AI模型推理参数
  options:
    temperature: 0.0      # 随机性控制，0.0=完全确定性，2.0=高随机性
    top_p: 0.3           # 核采样，控制候选词概率范围
    top_k: 10            # 限制每步考虑的候选词数量
    num_predict: 512     # 限制输出的最大token数量
    max_tokens: 512      # 外部模型使用（对应num_predict）
asr:
  language: zh
  model: fireredasr
  provider: cpu
  sample_rate: 16000
logging:
  format: '%(levelname)s: %(asctime)s %(name)s:%(lineno)s %(message)s'
  level: INFO
  # level: DEBUG
  log_file: null
processing:
  batch_size: 100
  enable_concurrent: false
  threads: 2
server:
  debug: false
  host: localhost
  port: 8000
  auto_reload_config: false  # 是否启用配置文件自动重载监听
storage:
  auto_backup: true
  download_dir: ./download
  export_excel: true
  models_dir: ./models
tts:
  chunk_size: 1024
  model: vits-zh-hf-theresa
  provider: cpu
  speed: 1.0

# 数据处理配置
data_processing:
  current_task_config: "driving_evaluation"  # 当前使用的任务配置文件名
  ai_processing_enabled: true                # 全局AI处理开关
  ai_timeout_per_record: 30                 # AI处理超时时间
  ai_retry_failed_records: false            # 是否重试失败记录
